# FIML_project

Alors que les systèmes d'apprentissage automatique sont de plus en plus adoptés pour des prises de décision à fort impact, leur manque d'impartialité devient préoccupant. En effet, ils peuvent occasionner de nombreux types de préjudices.
C'est ce que nous verrons en travaillant sur l'étude de cas de COMPAS (*Correctional Offender Management Profiling for Alternative Sanctions*). COMPAS est un outil de gestion de cas et d'aide à la décision utilisé par les tribunaux américains pour évaluer la probabilité qu'un défendeur devienne récidiviste.
Dans ce projet, nous voulons comprendre ce qui rend un modèle d'apprentissage automatique impartial et dans le cas contraire comment y remédier.
Il est ainsi nécessaire d'examiner comment ces modèles peuvent formaliser les préjugés et ce qui peut être envisagé pour corriger les prédictions biaisées.

## Membres

- Foux Quentin, quentin.foux@etu.umontpellier.fr
- Touzani Amine, amine.touzani@etu.umontpellier.fr
- Laabsi Zakaria zakaria.laabsi@etu.umontpellier.fr
- Sobolak Valérian valerian.sobolak@etu.montpellier.fr

## Bibliographie

- Eustasio del Barrio, Paula Gordaliza, and Jean-Michel Loubes. *Review of mathematical frameworks
for fairness in machine learning*, 2020. \
https://arxiv.org/pdf/2005.13755.pdf
- Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. *A survey
on bias and fairness in machine learning*, 2021. \
https://arxiv.org/pdf/1908.09635.pdf
- Farhan Rahman. *COMPAS Case Study: Fairness of a Machine Learning Model*, 2020.
https://towardsdatascience.com/compas-case-study-fairness-of-a-machine-learning-model-f0f804108751
- Amil Merchant. *Fairness in Machine Learning: Methods for Correcting Black-Box Algorithms*, 2019.
https://dash.harvard.edu/bitstream/handle/1/37364658/MERCHANT-SENIORTHESIS-2019.pdf?sequence=1&fbclid=IwAR1CBQ0gYYKfhhHAn5_6JWZ8Htn1PRPFHEe3OnODZAc3NUcfOtsnT8V_wtk
- Ziyuan Zhong. *A Tutorial on Fairness in Machine Learning*, 2018.
https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb
- olprod. *Impartialité de l’apprentissage automatique (préversion)*, 2021.
https://github.com/MicrosoftDocs/azure-docs.fr-fr/blob/master/articles/machine-learning/concept-fairness-ml.md
